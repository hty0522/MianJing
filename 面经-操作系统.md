操作系统

### 小点：

什么是 “可重入”，可重入就是说某个线程已经获得某个锁，可以再次获取锁而不会出现死锁



### 进程的几种状态

就绪状态&运行状态

可中断等待

不可中断等待

**这个等待状态与可中断等待状态的区别在于：处于TASK_UNINTERRUPTIBL状态的进程不能被信号量或者中断所唤醒，只有当它申请的资源有效时才能被唤醒。**

停止状态

中止状态



### 僵尸进程和孤儿进程

#### 僵尸进程

​		子进程先于父进程退出后，子进程的PCB需要其父进程释放，但是父进程并没有释放子进程的PCB，这样的子进程就称为僵尸进程。如果父进程是一个永不停止的进程，那子进程就会一直保持僵尸状态。 僵尸进程几乎不保留任何资源，只需父进程为他收尸。

​		僵尸进程太多会导致操作系统的进程数目过多，从而占满了OS的进程表。进而导致无法创建新进程，致使OS崩溃。

##### 如何解决

​		暴力做法，直接杀死父进程，那么它的子进程，即僵尸进程会变成孤儿进程，由系统来回收。

​		使用wait、waitpid方法		

​		**wait函数的原理**：进程调用wait，然后阻塞自己，然后寻找僵尸子进程，找到了则销毁子进程然后返回，没有找到则一直阻塞直到找到僵尸子进程为止；**和wait函数相比，waitpid其实是wait函数的封装，waitpid可以指定等待的子进程，并且指定返回的条件！**（父进程不会阻塞，相当于轮询）

#### 孤儿进程

​		父进程相对于子进程先退出，孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。系统会帮助父进程回收孤儿进程，所以孤儿进程不会一直占着系统资源。

### 常见的进程调度算法

先来先服务调度算法

最短作业优先算法

最高响应比优先算法

时间片轮转算法

细节暂时不整理了

#### CFS

​		cfs是一种新调度模型，它给每一个进程都设置一个虚拟时钟，如果一个进程得以执行，随着执行时间的不断增长，其vruntime也将不断增大，没有得到执行的进程vruntime将保持不变。
​		而调度器将会选择最小的vruntime那个进程来执行。这就是所谓的“完全公平”。**不同优先级的进程其vruntime增长速度不同，优先级高的进程vruntime增长得慢，所以它可能得到更多的运行机会。**

### ----------------------------

### IO多路复用

​		IO多路复用是一种**同步IO模型**，实现一个线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作， 多路是指网络连接，复用指的是同一个线程

​		没有IO多路复用机制时，有**同步阻塞**和**同步非阻塞**

​		**同步阻塞（BIO）**服务端采用单线程，当accept一个请求后，在recv或send调用阻塞时，将无法accept其他请求（必须等上一个请求处recv或send完），`无法处理并发`

![image-20220112205543013](面经-操作系统.assets\image-20220112205543013.png)

​		服务器端采用多线程，当accept一个请求后，开启线程进行recv，可以完成并发处理，但随着请求数增加需要增加系统线程，`大量的线程占用很大的内存空间，并且线程切换会带来很大的开销，10000个线程真正发生读写事件的线程数不会超过20%，每次accept都开一个线程也是一种资源浪费`

​		**同步非阻塞** ：服务器端当accept一个请求后，加入fds集合，每次轮询一遍fds集合recv(非阻塞)数据，没有数据则立即返回错误，`每次轮询所有fd（包括没有发生读写事件的fd）会很浪费cpu`

![image-20220112205643246](面经-操作系统.assets\image-20220112205643246.png)

#### IO多路复用（现在的做法）

​		服务器端采用单线程通过select/epoll等系统调用获取fd列表，遍历有事件的fd进行accept/recv/send，使其能`支持更多的并发连接请求`

fd指文件描述符

- ​	select

- ​	poll 与select相比，只是没有fd的限制

- ​	epoll

  ![image-20220112205621975](面经-操作系统.assets\image-20220112205621975.png)

#### **select缺点**

 		I/O多路复用支持只使用一个进程来维护多个 Socket。I/O 多路复用技术会用一个系统调用函数来监听我们所有关心的连接，也就说可以在一个监控线程里面监控很多的连接。只有当连接上有数据的时候，线程才去发起读请求。
 	
 	    select/poll/epoll 就是内核提供给用户态的多路复用系统调用，线程可以通过一个系统调用函数从内核中获取多个事件。


​        select实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。

        所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。
    
        select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。
​		**单个进程所打开的FD是有限制的**，通过FD_SETSIZE设置，默认1024

​		每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大

​		对socket扫描时是线性扫描，采用轮询的方法，效率较低（高并发时）

#### epoll工作方式

​		epoll会维护一个read_list的的双向链表，每一个socket会在来数据的时候会调用自身的callback函数，将当前的socket加入到readylist，然后唤醒epoll。被唤醒的epoll只需要遍历ready_list即可，raady_list一定有数据可读的socket。而不用做无用的遍历。

#### epoll缺点

​		只能工作在Linux下

#### epoll优点

- 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）
- 效率提升，不是轮询，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数 即**Epoll最大的优点就在于它只关心“活跃”的连接，而跟连接总数无关**，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll
- epoll通过内核和用户空间共享一块内存来实现的。（mmapx）

当连接数少的时候，可能用select效率会更好，毕竟回调函数的实现也需要时间。

#### **epoll LT 与 ET模式的区别**

- ​		epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。
- ​        LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作
- ​        ET模式下，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读完，或者遇到EAGAIN错误

![image-20220112195058689](面经-操作系统.assets\image-20220112195058689.png)

### ----------------------------

### 为什么要设置虚拟内存

​		内存和cpu一样都是稀缺资源，两个程序不能在内存重叠的情况下一起运行，因此可以借助交换内存，将暂时不用的内存先写入磁盘，需要时再读取回来。因此内存与内存之间并非完全连续。借助虚拟内存将进程和真实的物理内存连接起来，进程持有的虚拟地址通过内存管理单元（MMU）的映射关系，来转变为物理地址，再通过物理地址访问内存。

​		内存分段和内存分页都是操作虚拟地址和物理地址之间关系的方式，通过段号查询段表得到段基地址，再加上偏移量就是实际地址，但存在内存碎片和内存交换效率低的问题

​		内存分页是将虚拟和物理内存分割成一段段固定尺寸的大小（4KB），最小操作单位小，因此内存碎片和交换效率都有所改善。

根据页号查页表得到物理页号+偏移量  》〉》 页表数量太多，存储页表开销太大

​		因此有了多级页表，解决存储页表开销大的问题段式与页式并不是相对的，他们也可以组合在一起使用，在段的基础上进行分页分级，虚拟地址结构由**段号、段内页号和页内位移**三部分组成

​		TBL缓存，把最常用到的页表放到TBL缓存中去，命中了就直接得到物理地址，中不了再多级页表查找。



### 什么是操作系统内存

​		运行程序之前向操作系统申请内存，然后运行程序，一段时间后操作系统会来整理内存空间碎片，电脑上的程序运行是需要对应大小的物理内存。

#### SWAP内存（交换内存）

​		SWAP内存把不太常用的内存先写入磁盘中，然后释放这些内存。给更需要的进程使用，再次需要这些内存的时候再从磁盘中读取。

​		是磁盘上一块专门用于内存和磁盘交换的区域

#### 虚拟内存

​		实际上运行的进程并不是直接使用物理内存地址，而是把进程使用的内存地址与实际的物理内存地址做隔离，即操作系统会为每个进程分配独立的一套「**虚拟地址**」。

​		每个进程玩自己的地址，互不干涉，至于虚拟地址怎么映射到物理地址，对进程来说是透明的，操作系统已经把这些安排的明明白白了。操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来，如下图所示

- ​		进程中使用的内存地址叫虚拟地址
- ​		存在计算硬件里的空间地址叫物理地址

#### 操作系统是如何管理虚拟地址与物理内存地址之间关系?

#### 内存分段

​		程序包含若干个逻辑分段，如可由代码段、数据段、栈段、堆段组成，每个分段都有不同的属性，所以内存以分段的形式把这些段分离出来进行管理。

​		分段管理下的虚拟地址由两部分组成，**段号和段内偏移量**

​		1.通过段号映射段表的项

​		2.从项中获取到段基地址

​		3.段基地址+段内偏移量=使用的物理内存



![s](面经-操作系统.assets\image-20220112200651850.png)

好处：按照逻辑模块实现信息的共享和保护

两个不足：

- 内存碎片的问题
- 内存交换的效率低的问题

​		内存碎片整理通过内存交换的方式来实现，将内存上的程序加载到硬盘上去，再从硬盘读回来，内存交换空间，在 Linux 系统里，是我们常看到的 **Swap 空间**，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。



​		首先分段管理容易造成内存碎片，导致内存交换的频率较高，因为**硬盘的访问速度比内存慢太多了**，然后每次交换的时候，把一大段连续的内存写入到硬盘，再又从硬盘读取出来，如果交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿，过程也很慢的，所以说**分段方式内存交换效率低**。

#### 内存分页

​		缺点是不方便按照逻辑模块实现信息的共享和保护

​		内存碎片是由**多个不连续的小物理内存空间**造成，如果把这些不连续的小物理内存空间组合起来，是不是解决了这个问题？同样的，内存交换的时候我们保证交换的数据小，是不是能提高内存交换的效率？

​		这个办法就是内存分页，分页是把整个虚拟与物理空间切成一段段固定尺寸的大小，这样一个连续并且尺寸固定的空间，我们叫页，在 Linux 下，**每一页的大小为 4KB**。（虚拟空间是指存储一套虚拟地址的空间）

​		虚拟地址与物理地址是**通过页表来映射**，虚拟空间内的虚拟地址一定是连续的，物理地址不一定，但可以通过连续的虚拟地址把多个不连续的物理内存组合使用。



![image-20220112202733253](面经-操作系统.assets\image-20220112202733253.png)

1. 页号找到页表中的页项
2. 获取页项的物理页号基地址
3. 偏移量+物理页号基地址计算出物理内存地址

![image-20220112202903512](面经-操作系统.assets\image-20220112202903512.png)

每个进程分配一个页表，因为操作系统有非常多的进程，因此页表数量会很多，通过多级页表，可以节约内存

![image-20220112203347047](面经-操作系统.assets\image-20220112203347047.png)

#### TLB

​		多级页表虽然解决了空间上的问题，但是我们发现这种方式需要走多道转换才能找到映射的物理内存地址，经过的**多道转换造成了时间上的开销**。操作系统就利用这一特性，**把最多使用的几个页表项放到TLB缓存**, CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表，TLB 的命中率其实很高的，因为程序最常访问的页就那么几个。

**进程为什么慢**:

​		**页表的切换实质上导致TLB的缓存全部失效，这些寄存器里的内容需要全部重写。而线程切换无需经历此步骤。**

#### 内存段页

​		段式与页式并不是相对的，他们也可以组合在一起使用，在段的基础上进行分页分级

1. 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制 
2. 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页 

​		虚拟地址结构由**段号、段内页号和页内位移**三部分组成

<img src="面经-操作系统.assets\image-20220112203548746.png" alt="image-20220112203548746"  />

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号；
- 第三次将物理页号与页内位移组合，得到物理地址。

### ---------------------------

### 用户态与内核态

​		一般的操作系统对执行权限进行分级，分别为用用户态和内核态。用户态相较于内核态有**较低的执行权限**，很多操作是不被操作系统允许的，原因简单来说就是**用户态出现问题，也不能让操作系统崩溃呀。**内核态要维护系统的运行

​		内核态相当于一个介于硬件与应用之间的层，内核有ring 0的权限，可以执行任何cpu指令，也可以引用任何内存地址，包括外围设备, 例如硬盘, 网卡，权限等级最高。

#### 状态转换

​		用户程序跑在用户态下，但是如果需要执行一些操作例如**申请内存，网络读写**时，自己的权限不够，就需要转换到内核态去让内核的code帮忙干一些事情。下面三个方式是

######  a. 系统调用

​		这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使 用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

######  b. 异常

​		当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如**缺页异常**。

######  c. 外围设备的中断

​		当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到 内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

#### 为什么两者切换耗时

​		linux下每个进程的栈有两个，一个是**用户态栈，一个是内核态栈**。在需要从用户态栈切换到内核的时候，需要进行执行栈的转换，保存用户态的状态，包括寄存器状态，然后执行内核态操作，操作完成后要**恢复现场**，切换到用户态，这个过程是**耗时**的。

### -----------------------------

### 操作系统分配的进程空间是怎样的？线程能共享哪些？PCB

​		当一个新的进程创建的时候，会创建一个**进程控制模块pcb**，记录着该进程的具体信息，包**括进程信息，资源分配清单等**。同时操作系统会为其分配基本的栈空间，实际开始运行程序时因为还没有程序所以会先触发程序段缺页中断，操作系统加载所缺的程序，紧接着会触发数据块缺页中断，操作系统又加载所缺的数据。至于程序执行过程中所需的堆数据则是按需动态分配的。

​		先分配基本的栈空间（环境变量参数等）>>>部分加载代码段>>>部分加载数据段>>>动态分配堆

​		线程共享进程地址空间中除线程上下文信息中的所有内容，包括代码区（存放着编译后的可执行指令）、堆区、栈区（如果能拿到其他栈上的指针）、打开的文件

​		线程上下文：线程的栈区、程序计数器、栈指针以及函数运行使用的寄存器是线程私有的。

### -----------------------------

### 页面置换算法

#### 先进先出算法（FIFO）

​		此算法是淘汰最先进入内存的页面，选择在内存中驻留最久的页面予以淘汰，而替换此时需要调用的页面。

#### 最近最久未使用算法

​		其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”，因此必须单独设置一项用于记录页面的访问情况 ---- 手写LRU

### -----------------------------

### 死锁条件&解决方式：

（1） [互斥条件](https://www.zhihu.com/search?q=互斥条件&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"25677118"})：一个资源每次只能被一个进程使用。

（2） 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。

（3） 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。

（4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。

解决方式：

​	破坏上述四种条件之一

- ​		破坏互斥条件：CAS（COPPARE AND SWAP）CAS在每次执行时不一定会成功。如果执行CAS操作时目标字段的值已经被别的线程修改了，那么这次CAS操作就会失败

- ​		破坏请求和保持条件：一次原子性的获取所有需要的锁

- ​		破坏不剥夺条件：线程在获取后续锁失败时主动放弃已经持有的锁

- ​		破坏循环等待条件：按照逻辑顺序，为所有需要加锁的程序按照固定顺序加锁

  另外还可以在死锁发生后在解决